<!DOCTYPE html>
<html>
<head>
<title>README</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<style type="text/css">
/* GitHub stylesheet for MarkdownPad (http://markdownpad.com) */
/* Author: Nicolas Hery - http://nicolashery.com */
/* Version: b13fe65ca28d2e568c6ed5d7f06581183df8f2ff */
/* Source: https://github.com/nicolahery/markdownpad-github */

/* RESET
=============================================================================*/

html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, img, ins, kbd, q, s, samp, small, strike, strong, sub, sup, tt, var, b, u, i, center, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td, article, aside, canvas, details, embed, figure, figcaption, footer, header, hgroup, menu, nav, output, ruby, section, summary, time, mark, audio, video {
  margin: 0;
  padding: 0;
  border: 0;
}

/* BODY
=============================================================================*/

body {
  font-family: Helvetica, arial, freesans, clean, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  color: #333;
  background-color: #fff;
  padding: 20px;
  max-width: 960px;
  margin: 0 auto;
}

body>*:first-child {
  margin-top: 0 !important;
}

body>*:last-child {
  margin-bottom: 0 !important;
}

/* BLOCKS
=============================================================================*/

p, blockquote, ul, ol, dl, table, pre {
  margin: 15px 0;
}

/* HEADERS
=============================================================================*/

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
}

h1 tt, h1 code, h2 tt, h2 code, h3 tt, h3 code, h4 tt, h4 code, h5 tt, h5 code, h6 tt, h6 code {
  font-size: inherit;
}

h1 {
  font-size: 28px;
  color: #000;
}

h2 {
  font-size: 24px;
  border-bottom: 1px solid #ccc;
  color: #000;
}

h3 {
  font-size: 18px;
}

h4 {
  font-size: 16px;
}

h5 {
  font-size: 14px;
}

h6 {
  color: #777;
  font-size: 14px;
}

body>h2:first-child, body>h1:first-child, body>h1:first-child+h2, body>h3:first-child, body>h4:first-child, body>h5:first-child, body>h6:first-child {
  margin-top: 0;
  padding-top: 0;
}

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0;
}

h1+p, h2+p, h3+p, h4+p, h5+p, h6+p {
  margin-top: 10px;
}

/* LINKS
=============================================================================*/

a {
  color: #4183C4;
  text-decoration: none;
}

a:hover {
  text-decoration: underline;
}

/* LISTS
=============================================================================*/

ul, ol {
  padding-left: 30px;
}

ul li > :first-child, 
ol li > :first-child, 
ul li ul:first-of-type, 
ol li ol:first-of-type, 
ul li ol:first-of-type, 
ol li ul:first-of-type {
  margin-top: 0px;
}

ul ul, ul ol, ol ol, ol ul {
  margin-bottom: 0;
}

dl {
  padding: 0;
}

dl dt {
  font-size: 14px;
  font-weight: bold;
  font-style: italic;
  padding: 0;
  margin: 15px 0 5px;
}

dl dt:first-child {
  padding: 0;
}

dl dt>:first-child {
  margin-top: 0px;
}

dl dt>:last-child {
  margin-bottom: 0px;
}

dl dd {
  margin: 0 0 15px;
  padding: 0 15px;
}

dl dd>:first-child {
  margin-top: 0px;
}

dl dd>:last-child {
  margin-bottom: 0px;
}

/* CODE
=============================================================================*/

pre, code, tt {
  font-size: 12px;
  font-family: Consolas, "Liberation Mono", Courier, monospace;
}

code, tt {
  margin: 0 0px;
  padding: 0px 0px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px;
}

pre>code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent;
}

pre {
  background-color: #f8f8f8;
  border: 1px solid #ccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px;
}

pre code, pre tt {
  background-color: transparent;
  border: none;
}

kbd {
    -moz-border-bottom-colors: none;
    -moz-border-left-colors: none;
    -moz-border-right-colors: none;
    -moz-border-top-colors: none;
    background-color: #DDDDDD;
    background-image: linear-gradient(#F1F1F1, #DDDDDD);
    background-repeat: repeat-x;
    border-color: #DDDDDD #CCCCCC #CCCCCC #DDDDDD;
    border-image: none;
    border-radius: 2px 2px 2px 2px;
    border-style: solid;
    border-width: 1px;
    font-family: "Helvetica Neue",Helvetica,Arial,sans-serif;
    line-height: 10px;
    padding: 1px 4px;
}

/* QUOTES
=============================================================================*/

blockquote {
  border-left: 4px solid #DDD;
  padding: 0 15px;
  color: #777;
}

blockquote>:first-child {
  margin-top: 0px;
}

blockquote>:last-child {
  margin-bottom: 0px;
}

/* HORIZONTAL RULES
=============================================================================*/

hr {
  clear: both;
  margin: 15px 0;
  height: 0px;
  overflow: hidden;
  border: none;
  background: transparent;
  border-bottom: 4px solid #ddd;
  padding: 0;
}

/* TABLES
=============================================================================*/

table th {
  font-weight: bold;
}

table th, table td {
  border: 1px solid #ccc;
  padding: 6px 13px;
}

table tr {
  border-top: 1px solid #ccc;
  background-color: #fff;
}

table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

/* IMAGES
=============================================================================*/

img {
  max-width: 100%
}
</style>
</head>
<body>
<h1>DCASE 2018 - Task 5, Development dataset</h1>
<h2>Monitoring of domestic activities based on multi-channel acoustics</h2>
<p>Authors:</p>
<ul>
<li>Gert Dekkers (<a href="&#x6d;&#97;i&#x6c;&#x74;&#111;&#58;&#x67;&#x65;&#x72;t.&#x64;&#101;k&#107;&#101;&#x72;&#115;&#x40;&#107;&#117;&#108;&#x65;&#x75;&#x76;&#x65;&#x6e;&#x2e;&#98;&#101;">&#x67;&#101;&#x72;&#116;&#x2e;&#100;&#101;k&#x6b;e&#x72;&#115;&#x40;&#107;&#117;&#108;&#101;&#x75;&#x76;&#x65;n&#x2e;&#98;&#101;</a>, <a href="https://iiw.kuleuven.be/onderzoek/advise/People/Gert_Dekkers">https://iiw.kuleuven.be/onderzoek/advise/People/Gert_Dekkers</a>)</li>
<li>Peter Karsmakers (<a href="&#109;&#97;&#105;&#x6c;&#x74;&#111;&#x3a;&#x70;&#101;t&#x65;&#x72;&#46;k&#x61;&#114;&#115;&#x6d;&#x61;&#107;&#x65;&#114;&#115;&#x40;&#107;&#117;&#x6c;&#x65;&#x75;v&#x65;&#110;&#x2e;&#x62;&#101;">p&#x65;&#116;&#101;&#x72;&#46;&#107;&#x61;&#114;&#x73;&#109;&#97;&#107;&#101;&#x72;&#x73;&#64;&#107;&#117;&#108;&#101;&#117;&#118;&#x65;&#x6e;&#x2e;&#98;&#101;</a>, <a href="https://iiw.kuleuven.be/onderzoek/advise/People/PeterKarsmakers">https://iiw.kuleuven.be/onderzoek/advise/People/PeterKarsmakers</a>)</li>
</ul>
<p><a href="https://iiw.kuleuven.be/onderzoek/advise">Advanced Integrated Sensing lab (ADVISE)  / Department of Electrical Engineering (ESAT) / KU Leuven</a></p>
<p>Other (Recording, supervision, ...):</p>
<ul>
<li>Steven Lauwereins</li>
<li>Bart Thoen</li>
<li>Mulu Weldegebreal Adhana,</li>
<li>Henk Brouckxon</li>
<li>Bertold Van den Bergh</li>
<li>Toon van Waterschoot</li>
<li>Bart Vanrumste</li>
</ul>
<h1>Table of Contents</h1>
<ol>
<li><a href="#1-dataset">Dataset</a></li>
<li><a href="#2-content">Content</a></li>
<li><a href="#3-cross-validation-setup">Cross-validation setup</a></li>
<li><a href="#4-changelog">Changelog</a></li>
<li><a href="#5-license">License</a></li>
</ol>
<h1>1. Dataset</h1>
<p>The dataset is a derivative of the <strong>SINS dataset</strong>. The SINS dataset contains a continuous recording of one person living in a vacation home over a period of one week.  It was collected using a network of 13 microphone arrays distributed over the entire home. The microphone array consists of 4 linearly arranged microphones. For this dataset 4 microphone arrays in the combined living room and kitchen area are used. Figure 2 shows the floorplan of the recorded environment along with the position of the used sensor nodes.
<figure>
    <p align="center">
        <img src="http://d33wubrfki0l68.cloudfront.net/5cb3f5d055aa8916eaafa831fefea69c113cbc5c/c201d/images/tasks/challenge2018/task5_2dplan.png" class="img img-responsive" style="width: 300px" align="center">
    </p>
	<p align="center">
        <figcaption>Figure 2: 2D floorplan of the combined kitchen and living room with the used sensor nodes.</figcaption>
    </p>
</figure>
<br>
Approximately 200 hours of data from 4 sensor nodes are taken from the SINS dataset. The partitioning of the data was done randomly. The segments belonging to one particular consecutive activity (e.g. a full session of cooking) were kept together. The data provided for each sensor node contain recordings of the same time period. This means that the performed activities are observed from multiple microphone arrays at the same time instant. </p>
<p>The recordings were split into audio segments of 10s. Each segment represents one activity.  These audio segments are provided as individual files along with the ground truth. 
The daily activities for this dataset (9) are shown in Table 1 along with the available 10s segments in the dataset and the amount of full sessions of a certain activity (e.g. a cooking session).</p>
<div class="table table-responsive">
<table class="table table-striped">
    <thead>
        <tr>
            <th>Activity</th>
            <th class="col-md-3"># 10s segments</th>
            <th class="col-md-3"># sessions</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Absence (nobody present in the room)</td>
            <td>18860</td>
            <td>42</td>
        </tr>
        <tr>
            <td>Cooking</td>
            <td>5124</td>
            <td>13</td>
        </tr>
        <tr>
            <td>Dishwashing</td>
            <td>1424</td>
            <td>10</td>
        </tr>
        <tr>
            <td>Eating</td>
            <td>2308</td>
            <td>13</td>
        </tr>
        <tr>
            <td>Other (present but not doing any relevant activity)</td>
            <td>2060</td>
            <td>118</td>
        </tr>  
        <tr>
            <td>Social activity (visit, phone call)</td>
            <td>4944</td>
            <td>21</td>
        </tr>
        <tr>
            <td>Vacuum cleaning</td>
            <td>972</td>
            <td>9</td>
        </tr> 
        <tr>
            <td>Watching TV</td>
            <td>18648</td>
            <td>9</td>
        </tr>
        <tr>
            <td>Working (typing, mouse click, ...)</td>
            <td>18644</td>
            <td>33</td>
        </tr>
    </tbody>
    <tfoot>
        <tr>
            <td><strong>Total</strong></td>
            <td><strong>72984</strong></td>
            <td><strong>268</strong></td>
        </tr>
    </tfoot>
</table>
</div>
<div class="clearfix"></div>
<h3>Recording and annotation procedure</h3>
<p>The sensor node configuration used in this setup is a control board together with a linear microphone array. The control board contains an EFM32 ARM cortex M4 microcontroller from Silicon Labs (EFM32WG980) used for sampling the analog audio. The microphone array contains four Sonion N8AC03 MEMS low-power (±17µW) microphones with an inter-microphone distance of 5 cm. The sampling for each audio channel is done sequentially at a rate of 16 kHz with a bit depth of 12.
The annotation was performed in two phases. First, during the data collection a smartphone application was used to let the monitored person(s) annotate the activities while being recorded. The person could only select a fixed set of activities. The application was easy to use and did not significantly influence the transition between activities. Secondly, the start and stop timestamps of each activity were refined by using our own annotation software. Postprocessing and sharing the database involves privacy-related aspects. Besides the person(s) living there, multiple people visited the home. Moreover, during a phone call, one can partially hear the person on the other end. A written informed consent was obtained from all participants.</p>
<h1>2. Content</h1>
<p>The content of the dataset is structured in the following manner:</p>
<pre><code>dataset root
│   EULA.pdf                End user license agreement
│   meta.txt                meta data, tsv-format, [audio file (str)][tab][label (str)][tab][session (str)]
│   readme.md               Dataset description (markdown)
│   readme.html             Dataset description (HTML)
│
└───audio                   72984 audio segments, 16-bit 16kHz
│   │   DevNode1_ex1_1.wav  name format DevNode{NodeID}_ex{sessionID}_{segmentID}.wav
│   │   DevNode2_ex1_2.wav
│   │   ...
│
└───evaluation_setup        cross-validation setup, 4 folds
    │   fold1_train.txt     training file list, tsv-format, [audio file (str)][tab][label (str)][tab][session (str)]
    │   fold1_test.txt      test file list, tsv-format, [audio file (str)][tab][label (str)]  
    │   ...        
</code></pre>

<p>The multi-channel audio files can be found under directory <code>audio</code> and are formatted in the following manner:</p>
<pre><code>DevNode{NodeID}_ex{sessionID}_{segmentID}.wav
</code></pre>

<ul>
<li><em>{NodeID}</em> (1-4) is an identifier to indicate which segments belong to a specific node. In total 4 nodes are given (1-4). It is unknown what the location of the node is to the user.</li>
<li><em>{sessionID}</em> indicates a full session of a certain activity.</li>
<li><em>{segmentID}</em> indicates a segment belonging to a certain {sessionID}. A session of a certain activity (e.g. cooking) can have multiple 10s segments.</li>
</ul>
<p>The file <code>meta.txt</code> and the content of the folder <code>evaluation_setup</code> contain filenames along with ground truth labels and an identifier of to which session the segment belongs. These are arranged in the following manner:</p>
<pre><code>[filename (str)][tab][activity label (str)][tab][session (str)]
</code></pre>

<p>The directory <code>evaluation_setup</code> provides cross-validation folds for the development dataset. More information on the usage can be read <a href="#usage">here</a></p>
<h1>3. Cross-validation setup</h1>
<p>The dataset includes multi-channel audio segments along with the ground truth and cross-validation folds.
Cross-validation folds are provided for the dataset in order to make results reported with this dataset uniform. The setup consists of four folds distributing the available files. 
Segments belonging to a particular session of an activity (e.g. a session of cooking collected by multiple sensor nodes) are kept together to minimize leakage between folds. The folds are provided with the dataset in the directory <code>evaluation setup</code>. For each fold a training, testing and evaluation subset is provided. </p>
<h4>Training</h4>
<p><code>evaluation setup\fold[1-4]_train.txt</code>
: training file list (in csv-format)</p>
<p>Format:</p>
<pre><code>[filename (str)][tab][activity label (str)][tab][session (str)]
</code></pre>

<h4>Testing</h4>
<p><code>evaluation setup\fold[1-4]_test.txt</code>
: testing file list (in csv-format)</p>
<p>Format:</p>
<pre><code>[filename (str)][tab]
</code></pre>

<h4>Evaluating</h4>
<p><code>evaluation setup\fold[1-4]_evaluate.txt</code>
: evaluation file list (in csv-format), same as fold[1-4]_test.txt but with additional reference information. These two files are provided separately to prevent contamination with ground truth when testing the system</p>
<p>Format: </p>
<pre><code>[filename (str)][tab][activity label (str)]
</code></pre>

<h1>4. Changelog</h1>
<h4>1.0.1 / 2017-04-12</h4>
<ul>
<li>Added eval folds to folder 'evaluation_setup'</li>
<li>Added README.md</li>
</ul>
<h4>1.0.1 / 2017-03-30</h4>
<ul>
<li>Fixed error in dataset. The error caused duplicate segments.</li>
</ul>
<h4>1.0.0 / 2018-03-21</h4>
<ul>
<li>Initial commit</li>
</ul>
<h1>5. License</h1>
<p>See file <a href="EULA.pdf">EULA.pdf</a></p>

</body>
</html>
<!-- This document was created with MarkdownPad, the Markdown editor for Windows (http://markdownpad.com) -->
